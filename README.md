# Malware-URL
Web service which informs if a website has malware or not

## Getting Started

This document explains how to successfully call the Malware url lookup API

### Before You Start

You will need the following prerequites 

* Python 3+ version
* Flask 
* Sqlite3

#### 1. Installing Python

Use this link to download and install python 3+ on your system
https://www.python.org/downloads/

Make sure to check add python to path checkbox for windows installation

#### 2. Installing Dependencies

For flask 

pip intsall flask

for sqlite3

pip install sqlite

Note: if this doesnt work for your system try using a virtual environment and make use of pip3 while intsalling

### Running the Service

Clone the project using the link https://github.com/therealameya/Malware-URL.git

Or

Simply download the zip and export it to a folder

Open the terminal(command line / powershell) in the folder you extracted the project and run this command.

For Linux and Mac:
export FLASK_APP=app.py

For Windows:
set FLASK_APP=app.py

Now type "flask run" in terminal this would run the flask project i.e. the web service.


#### 2. Install Postman

We would need postman to pass header with out GET requests 

https://www.postman.com/downloads/


## API Documentation

For using any of the available endpoint we would need to first add header with key name "api_key" and value as "abc123"

Go in the Authorization sections, select "API KEY" from the drop down and add this key name "api_key" and value as "abc123"

![Postman](postman.png)


### Get URL Info

```
GET /v1/urlinfo/{resource_url_with_query_string}
```

| Header | Type | Description |
| :--- | :--- | :--- |
| `api_key` | `string` | **Required**. Your Access API key |


### Respone Structure
```
{
    "safe": true,
    "details": {
        "type": "",
        "date_added": ""
    }
}
```
If the URL is known to contain malware, the safe field would be 'false' and the details field would contain information about the type of  malware. If the URL is not known to contain any malware, the safe field would be true and the details field would be empty.

**Example 1**

#### Request

Here,

url = abc.com, 
api_key = abc123

```
http://127.0.0.1:5000/v1/urlinfo/abc.com
```
```
header = {'api_key': 'abc123' }
```

CURL version 

```
curl --location --request GET 'http://127.0.0.1:5000/v1/urlinfo/abc.com' \
--header 'api_key: abc123'
```


Here,

url = abc.com
api_key = abc123

#### Response

```
{
	"safe":false,
	"details": {
		"date_added":"2022-01-01",
		"type":"Trojan",
		"url":"abc.com"
	}
}
```

As the URL is known to contain malware, the safe field returns false and the details field contain information about the malware type. 


**Example 2** 

#### Request

Here,

url = abc.com, 
api_key = abc123

```
http://127.0.0.1:5000/v1/urlinfo/abc1.com
```

```
header = {'api_key': 'abc123' }
```

```
curl --location --request GET 'http://127.0.0.1:5000/v1/urlinfo/abc1.com' \
--header 'api_key: abc123'
```

#### Response

```
{"safe":true}
```

As the URL is known to contain malware, the safe field returns true and returns no details section.

### Add URL endpoint

This API endpoint can be used report a about a malware url to our service

```
GET /v1/addurl{paramters}
```

| Parameter | Type | Description |
| :--- | :--- | :--- |
| `url` | `string` | **Required**. URL with Malware |
| `type` | `string` | **Required**. Type of Malware |

| Header | Type | Description |
| :--- | :--- | :--- |
| `api_key` | `string` | **Required**. Your Access API key |

**Example 1**


#### Request
```
http://localhost:5000/v1/addurl?url=example2.com&type=Trojan
```

```
header = {'api_key': 'abc123' }
```


```
curl --location --request GET 'http://localhost:5000/v1/addurl?type=Trojan&url=example3.com' \
--header 'api_key: abc123'
```



#### Response
```
{"success":true}
```

### Authentication

So, here we take an API key in request header, then we validate the API key to check if it has valid roles (authorization) and it exists in the user database.
For this project demo we are not using the user_db but simply created a mock list to mimic user database.

The function isValidAPIkey check if API key is present in the our record and if had valid authorization. i.e. in our case it checks teh role for the given API key and only return true if the role is admin.

Further we can add more code to check if the particular role is allowed to access the requested API, if its not allowed then return status code 403 Forbidden.


### BONUS


Q1. The size of the URL list could grow infinitely, how might you scale this beyond the memory capacity of the system? 

We can make use of some techniques for scaling out storage systems to support large number of URLs

* Use caching for storing heavily requested URLs, we can use Redis or Memcached, to store the most recently accessed URLs in memory, so that you don't have to look them up in the database each time. This would reduce the load on the database and improve the performance of the service.

* Distributed storage: Instead of storing all of the URLs in a single database, we could use a distributed storage system, such as Apache Cassandra or MongoDB, to store the URLs across multiple servers. This would allow you to scale the service horizontally and handle a larger volume of URLs. eg.  For store .us domains in USA DB server whereas store .eu domains in Europe DB servers etc.

* DB Sharding - We need use MongoDB, as it supports sharding. We can shard URL list across multiple servers to distribute the load and improve the performance of the service.

* Indexing - We have already implemented indexing on the url column, its speeds up the query and improves the performance of the system.

* Internal and External Load Balancers : We can use load balancing to distribute the requests across multiple instances of the service. This would allow the service to scale horizontally and handle a higher volume of requests.

Here is the System design for scalable system.

![System Design](malware.drawio.png)


Q2. The number of requests may exceed the capacity of this system, how might you solve that?

We can use the system design mentioned above to solve the problem.

* Use load balancing to use more servers for increased loads. We can use load balancers between caller and service, and between service and cache or cache and DB wherever we need to scale in case of a large number of requests.

* Asynchronous processing : We could use an asynchronous task queue, such as RabbitMQ or Celery, to process the requests in the background. This would allow the service to respond to requests more quickly and scale better under high load.

* If one caller is sending more requests than expected then use the rate limiting to control the number of requests from the caller. For example, if a service can allow 10 requests in 5mins and the caller sends more than 10 requests in the 5mins gap then we send back an error 429 too many requests and not process it further.


Q3.  What are some strategies you might use to update the service with new URLs? Updates may be as many as 5000 URLs a day with updates arriving every 10 minutes


* Batch Updates : We are getting around 5000 urls a day so we are basically writing the same query to insert into the table just with different urls. Instead what we  can do is store all the urls that came in that span of 10 minutes in some buffer storage or a temporary file. And instead of writing insert query for all the urls in the buffer storage we can just write one insert with multiple entries. This will increase the performance since the database has to parse INSERT statement only once rather than one for each url.


Also there are few drawbacks of getting the update every 10 minute. First being updating the database meaning opening the connection to database and closing it every 10 minute, this might result in overhead of opening and closing the connection again and again. 

* Connection Pool : One solution to this problem is using the connection pool. It is a cache of connections where multiple clients can use the connections in the cache. Suppose a client wants to connect to database( here in our case every ten minute ) at any given time instead of creating a new connection it uses the connection from this pool. And instead of closing the connection it is returned back to the pool. This technique improves the performance because we can also specify the maximum amount of connections that can be made at a given time in the pool and also saves us the overhead of creating and closing the connection every-time.  the There are many different connection pooling libraries available for different programming languages and database systems. There is a third party library called PySQLitePool which can be used in the service that I have created using sqlite. 
